{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11a55d3",
   "metadata": {},
   "source": [
    "# Machine learning and statistical learning\n",
    "\n",
    "## Training/ Validation/ Test Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90efd10b",
   "metadata": {},
   "source": [
    "### 1 Context and objectives\n",
    "\n",
    "In this notebook, I will predict a continuous variable using a machine learning algorithm by varying the values of a hyperparameter of this algorithm. The objective is to observe the evolution of the measurement error on the training sample as well as on the test sample, according to the flexibility of the model.\n",
    "\n",
    "The data used in this exercise give information about the target variable, the selling price of cars (in rupees) and provide details on the characteristics of the car. The dataset was downloaded from Kaggle (https://www.kaggle.com/datasets/nehalbirla/vehicle-dataset-from-cardekho) and cleaned.\n",
    "\n",
    "The columns of the dataset are the following:\n",
    "\n",
    "• `name`: name of the car\n",
    "\n",
    "• `year`: year in which the car was bought\n",
    "\n",
    "• `selling_price`: price the owner wants to sell the car at (in thousand rupees)\n",
    "\n",
    "• `km_driven`: distance completed by the car in km\n",
    "\n",
    "• `fuel`: fuel type of the car\n",
    "\n",
    "• `seller_type`: tells if car is sold by individual or dealer\n",
    "\n",
    "• `transmission`: Gear transmission of the car (Automatic/Manual)\n",
    "\n",
    "• `owner`: number of previous owners\n",
    "\n",
    "• `mileage`: mileage of the car\n",
    "\n",
    "• `engine`: engine capacity of the car\n",
    "\n",
    "• `max_power`: max power of engine\n",
    "\n",
    "• `torque`: torque of the car\n",
    "\n",
    "• `seats`: number of seats in the car\n",
    "\n",
    "• `sample`: whether the observation belongs to the training or testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d03ae6",
   "metadata": {},
   "source": [
    "### 2. First steps: preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f11a67b",
   "metadata": {},
   "source": [
    "**1. From AMeTICE, download the cars dataset (cars.csv)**\n",
    "\n",
    "**2. Load the CSV file into R or Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a062d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AMSE\\Documents\\Thu_Ha\\ML_SL\\cars_project\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti Swift Dzire VDI</td>\n",
       "      <td>2014</td>\n",
       "      <td>450000</td>\n",
       "      <td>145500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>23.40</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>74.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skoda Rapid 1.5 TDI Ambition</td>\n",
       "      <td>2014</td>\n",
       "      <td>370000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Second Owner</td>\n",
       "      <td>21.14</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>103.52</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda City 2017-2020 EXi</td>\n",
       "      <td>2006</td>\n",
       "      <td>158000</td>\n",
       "      <td>140000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Third Owner</td>\n",
       "      <td>17.70</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>78.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hyundai i20 Sportz Diesel</td>\n",
       "      <td>2010</td>\n",
       "      <td>225000</td>\n",
       "      <td>127000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maruti Swift VXI BSIII</td>\n",
       "      <td>2007</td>\n",
       "      <td>130000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>16.10</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>88.20</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  year  selling_price  km_driven    fuel  \\\n",
       "0        Maruti Swift Dzire VDI  2014         450000     145500  Diesel   \n",
       "1  Skoda Rapid 1.5 TDI Ambition  2014         370000     120000  Diesel   \n",
       "2      Honda City 2017-2020 EXi  2006         158000     140000  Petrol   \n",
       "3     Hyundai i20 Sportz Diesel  2010         225000     127000  Diesel   \n",
       "4        Maruti Swift VXI BSIII  2007         130000     120000  Petrol   \n",
       "\n",
       "  seller_type transmission         owner  mileage  engine  max_power  seats  \n",
       "0  Individual       Manual   First Owner    23.40  1248.0      74.00    5.0  \n",
       "1  Individual       Manual  Second Owner    21.14  1498.0     103.52    5.0  \n",
       "2  Individual       Manual   Third Owner    17.70  1497.0      78.00    5.0  \n",
       "3  Individual       Manual   First Owner    23.00  1396.0      90.00    5.0  \n",
       "4  Individual       Manual   First Owner    16.10  1298.0      88.20    5.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "path_data = \".\\data\\cars.csv\"\n",
    "cars_data = pd.read_csv(path_data, header = 0)\n",
    "cars_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401e6547",
   "metadata": {},
   "source": [
    "**3. Randomly split your dataset into two parts:**\n",
    "\n",
    "a) a train set that will contain 80% of the observations\n",
    "\n",
    "b) a test set that will contain the remaining 20%.\n",
    "\n",
    "**4. From the train set, create two datasets:**\n",
    "\n",
    "a) a training set that will contain 80% of the observations from the train set\n",
    "\n",
    "b) a validation set that waill contain the remining 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00f875cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (6502, 12)\n",
      "Test shape: (1626, 12)\n",
      "Training shape: (5201, 12)\n",
      "Validation shape: (1301, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(cars_data, test_size = 0.20, random_state = 0)\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Test shape:\", test.shape)\n",
    "\n",
    "training, validation = train_test_split(train, test_size = 0.20, random_state = 0)\n",
    "print(\"Training shape:\", training.shape)\n",
    "print(\"Validation shape:\", validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e33d28",
   "metadata": {},
   "source": [
    "### 3. Getting to know the data: descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0301edea",
   "metadata": {},
   "source": [
    "**1. Compute some summary statistics for the whole dataset (and comment the outputs):**\n",
    "\n",
    "a) for numerical variables: mean, minimum, maximum, quartiles\n",
    "\n",
    "b) for categorical variables: for each category: proportion of observations; mean, minimum, maximum, quartiles of the target variable (selling_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5794dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For numerical independent variables\n",
    "\n",
    "# year: year in which the car was bought\n",
    "\n",
    "cars_data[\"year\"].mean()\n",
    "print(\"The average year in which the cars were bought is %d.\" % (int(cars_data[\"year\"].mean())))\n",
    "cars_data[\"year\"].max()\n",
    "print(\"The newest cars were bought in %d.\" % (cars_data[\"year\"].max()))\n",
    "cars_data[\"year\"].min()\n",
    "print(\"The oldest cars were bought in %d.\" % (cars_data[\"year\"].min()))\n",
    "st_quartile_year = int(np.percentile(cars_data[\"year\"], 25))\n",
    "median_year = int(np.percentile(cars_data[\"year\"], 50))\n",
    "rd_quartile_year = int(np.percentile(cars_data[\"year\"], 75))\n",
    "print(f\"The 1st, median and 3rd quartiles of the year in which the cars were bought are {st_quartile_year}, {median_year}, {rd_quartile_year}, respectively.\")\n",
    "\n",
    "# km_driven: distance completed by the car in km\n",
    "\n",
    "cars_data[\"km_driven\"].mean()\n",
    "print(\"The average distance the cars have driven is %d.\" % (int(cars_data[\"km_driven\"].mean())))\n",
    "cars_data[\"km_driven\"].max()\n",
    "print(\"The highest distance a car has driven is %d.\" % (cars_data[\"km_driven\"].max()))\n",
    "cars_data[\"km_driven\"].min()\n",
    "print(\"The lowest distance a car has driven is %d.\" % (cars_data[\"km_driven\"].min()))\n",
    "st_quartile_km_driven = int(np.percentile(cars_data[\"km_driven\"], 25))\n",
    "median_km_driven = int(np.percentile(cars_data[\"km_driven\"], 50))\n",
    "rd_quartile_km_driven = int(np.percentile(cars_data[\"km_driven\"], 75))\n",
    "print(f\"The 1st, median and 3rd quartiles of the distances that the cars have driven are {st_quartile_km_driven}, {median_km_driven}, {rd_quartile_km_driven}, respectively.\")\n",
    "\n",
    "# mileage: mileage of the car\n",
    "\n",
    "cars_data[\"mileage\"].mean()\n",
    "print(\"The average number of mileage that the cars have is %d.\" % (int(cars_data[\"mileage\"].mean())))\n",
    "cars_data[\"mileage\"].max()\n",
    "print(\"The highest number of mileage a car has is %d.\" % (cars_data[\"mileage\"].max()))\n",
    "cars_data[\"mileage\"].min()\n",
    "print(\"The lowest number of mileage a car has is %d.\" % (cars_data[\"mileage\"].min()))\n",
    "st_quartile_mileage = int(np.percentile(cars_data[\"mileage\"], 25))\n",
    "median_mileage = int(np.percentile(cars_data[\"mileage\"], 50))\n",
    "rd_quartile_mileage = int(np.percentile(cars_data[\"mileage\"], 75))\n",
    "print(f\"The 1st, median and 3rd quartiles of the number of mileage that the cars have are {st_quartile_mileage}, {median_mileage}, {rd_quartile_mileage}, respectively.\")\n",
    "\n",
    "# engine: engine capacity of the car\n",
    "\n",
    "cars_data[\"engine\"].mean()\n",
    "print(\"The average engine capacity the cars have is %d.\" % (int(cars_data[\"engine\"].mean())))\n",
    "cars_data[\"engine\"].max()\n",
    "print(\"The highest engine capacity a car has is %d.\" % (cars_data[\"engine\"].max()))\n",
    "cars_data[\"engine\"].min()\n",
    "print(\"The lowest engine capacity a car has is %d.\" % (cars_data[\"engine\"].min()))\n",
    "st_quartile_engine = int(np.nanpercentile(cars_data[\"engine\"], 25))\n",
    "median_engine = int(np.nanpercentile(cars_data[\"engine\"], 50))\n",
    "rd_quartile_engine = int(np.nanpercentile(cars_data[\"engine\"], 75))\n",
    "print(f\"The 1st, median and 3rd quartiles of the engine capacity that the cars have are {st_quartile_engine}, {median_engine}, {rd_quartile_engine}, respectively.\")\n",
    "\n",
    "# max_power: max power of engine\n",
    "\n",
    "cars_data[\"max_power\"].mean()\n",
    "print(\"The average max power of engine the cars have is %d.\" % (int(cars_data[\"max_power\"].mean())))\n",
    "cars_data[\"max_power\"].max()\n",
    "print(\"The highest max power of engine a car has is %d.\" % (cars_data[\"max_power\"].max()))\n",
    "cars_data[\"max_power\"].min()\n",
    "print(\"The lowest max power of engine a car has is %d.\" % (cars_data[\"max_power\"].min()))\n",
    "st_quartile_max_power = int(np.nanpercentile(cars_data[\"max_power\"], 25))\n",
    "median_max_power = int(np.nanpercentile(cars_data[\"max_power\"], 50))\n",
    "rd_quartile_max_power = int(np.nanpercentile(cars_data[\"max_power\"], 75))\n",
    "print(f\"The 1st, median and 3rd quartiles of the max power of engine that the cars have are {st_quartile_max_power}, {median_max_power}, {rd_quartile_max_power}, respectively.\")\n",
    "\n",
    "# seats: number of seats in the car\n",
    "\n",
    "cars_data[\"seats\"].mean()\n",
    "print(\"The average number of seats in the car is %d.\" % (int(cars_data[\"seats\"].mean())))\n",
    "cars_data[\"seats\"].max()\n",
    "print(\"The highest number of seats in the car is %d.\" % (cars_data[\"seats\"].max()))\n",
    "cars_data[\"seats\"].min()\n",
    "print(\"The lowest number of seats in the car is %d.\" % (cars_data[\"seats\"].min()))\n",
    "st_quartile_seats = int(np.nanpercentile(cars_data[\"seats\"], 25))\n",
    "median_seats = int(np.nanpercentile(cars_data[\"seats\"], 50))\n",
    "rd_quartile_seats = int(np.nanpercentile(cars_data[\"seats\"], 75))\n",
    "print(f\"The 1st, median and 3rd quartiles of the number of seats in the car are {st_quartile_seats}, {median_seats}, {rd_quartile_seats}, respectively.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4190b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For categorical variables \n",
    "\n",
    "# fuel: fuel type of the car\n",
    "\n",
    "df_fuel = pd.DataFrame(cars_data[\"fuel\"].value_counts(normalize=True))\n",
    "print(\"The proprotion of diesel is %d, the proportion of petrol is %d, the proportion of CNG is %d, and the proportion of LPG is %d.\" % ((df_fuel.at[\"Diesel\", \"fuel\"]*100), (df_fuel.at[\"Petrol\", \"fuel\"]*100), (df_fuel.at[\"CNG\", \"fuel\"]*100), (df_fuel.at[\"LPG\", \"fuel\"]*100)))\n",
    "\n",
    "# seller_type: tells if car is sold by individual or dealer\n",
    "\n",
    "df_seller_type = pd.DataFrame(cars_data[\"seller_type\"].value_counts(normalize=True))\n",
    "print(\"The proprotion of cars sold by an individual is %d, the proportion of cars sold by a dealer is %d, the proportion of cars sold by a trustmark dealer is %d.\" % ((df_seller_type.at[\"Individual\", \"seller_type\"]*100), (df_seller_type.at[\"Dealer\", \"seller_type\"]*100), (df_seller_type.at[\"Trustmark Dealer\", \"seller_type\"]*100)))\n",
    "\n",
    "# transmission: gear transmission of the car (Automatic/Manual)\n",
    "\n",
    "df_transmission = pd.DataFrame(cars_data[\"transmission\"].value_counts(normalize=True))\n",
    "print(\"The proprotion of cars having automatic gear transmission is %d, the proportion of cars having manual gear transmission is %d.\" % ((df_transmission.at[\"Automatic\", \"transmission\"]*100), (df_transmission.at[\"Manual\", \"transmission\"]*100)))\n",
    "\n",
    "# owner: number of previous owners\n",
    "\n",
    "df_owner = pd.DataFrame(cars_data[\"owner\"].value_counts(normalize=True))\n",
    "print(\"The proprotion of cars having one owner is %d, the proportion of cars having two owners is %d, the proportion of cars having three owners is %d, the proportion of cars having three or more owners is %d, the proportion of test drive car is %d.\" % ((df_owner.at[\"First Owner\", \"owner\"]*100), (df_owner.at[\"Second Owner\", \"owner\"]*100), (df_owner.at[\"Third Owner\", \"owner\"]*100), (df_owner.at[\"Fourth & Above Owner\", \"owner\"]*100), (df_owner.at[\"Test Drive Car\", \"owner\"]*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca24b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our target variable\n",
    "\n",
    "# selling_price: price the owner wants to sell the car at (in thousand rupees)\n",
    "\n",
    "cars_data[\"selling_price\"].mean()\n",
    "print(\"The average selling price is %d thousand rupees.\" % (int(cars_data[\"selling_price\"].mean())))\n",
    "cars_data[\"selling_price\"].max()\n",
    "print(\"The highest selling price is %d thousand rupees.\" % (cars_data[\"selling_price\"].max()))\n",
    "cars_data[\"selling_price\"].min()\n",
    "print(\"The lowest selling price is %d thousand rupees.\" % (cars_data[\"selling_price\"].min()))\n",
    "st_selling_price = int(np.percentile(cars_data[\"selling_price\"], 25))\n",
    "median_selling_price = int(np.percentile(cars_data[\"selling_price\"], 50))\n",
    "rd_selling_price = int(np.percentile(cars_data[\"selling_price\"], 27))\n",
    "print(f\"The 1st, median and 3rd quartiles of the selling price are {st_selling_price}, {median_selling_price}, {rd_selling_price} thousand rupees, respectively.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6b0d3b",
   "metadata": {},
   "source": [
    "**2. Create graphs to show the relationship between the target variable and the explanatory variables. Comment on these.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3180f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The relationship between \"selling_price\" and \"year\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(cars_data[\"year\"], cars_data[\"selling_price\"], c = \"green\")\n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"selling_price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733dc895",
   "metadata": {},
   "source": [
    "*Comment: As can be seen from the graph, there is a positive relationship between the selling price and the year in which the cars were bought; or in other words, the newer the cars in terms of the year in which they were bought, the higher their secondhand prices.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a66375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The relationship between \"selling_price\" and \"km_driven\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(cars_data[\"km_driven\"], cars_data[\"selling_price\"], c = \"pink\")\n",
    "plt.xlabel(\"km_driven\")\n",
    "plt.ylabel(\"selling_price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b646d9c2",
   "metadata": {},
   "source": [
    "*Comment: The graph shows a negative relationship between the selling price and the km driven of the cars. Specifically, the lower the km driven (which can be considered as an indicator of how new the car is), the higher the secondhand price.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f1e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The relationship between \"selling_price\" and \"fuel\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(cars_data[\"fuel\"], cars_data[\"selling_price\"], c = \"orange\")\n",
    "plt.xlabel(\"fuel\")\n",
    "plt.ylabel('selling_price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a323e85",
   "metadata": {},
   "source": [
    "*Comment: It can be seen that among the four types of fuel, the cars run by diesel or pertrol tend to be bought with higher seconhand price than that of LPG or CNG.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15697b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The relationship between \"selling_price\" and \"seller_type\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(cars_data[\"seller_type\"], cars_data[\"selling_price\"], c = \"blue\")\n",
    "plt.xlabel(\"seller_type\")\n",
    "plt.ylabel(\"selling_price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a44625d",
   "metadata": {},
   "source": [
    "*Comment: It is hard to tell if there is any clear relationship between the selling price and the seller type from this graph.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078a08b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The relationship between \"selling_price\" and \"transmission\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(cars_data[\"transmission\"], cars_data[\"selling_price\"], c = \"brown\")\n",
    "plt.xlabel(\"transmission\")\n",
    "plt.ylabel(\"selling_price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0780c65",
   "metadata": {},
   "source": [
    "*Comment: From this graph, it can be said that the automatic cars tend to be bought at higher price than the manual cars.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba05ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The relationship between \"selling_price\" and \"owner\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(cars_data[\"owner\"], cars_data[\"selling_price\"], c = \"purple\")\n",
    "plt.xlabel(\"owner\")\n",
    "plt.ylabel(\"selling_price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f894936",
   "metadata": {},
   "source": [
    "*Comment: There is a pretty clear trend from this graph, the cars owned by fewer owners (again, number of owner can be seen as another indicator of how new the car is) tend to have higher secondhand prices.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8332d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The relationship between \"selling_price\" and \"mileage\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(cars_data[\"mileage\"], cars_data[\"selling_price\"], c = \"yellow\")\n",
    "plt.xlabel(\"mileage\")\n",
    "plt.ylabel(\"selling_price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7edd81",
   "metadata": {},
   "source": [
    "*Comment: It is hard to tell if there is any clear relationship between the selling price and the mileage from this graph.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65e75ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The relationship between \"selling_price\" and \"engine\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(cars_data[\"engine\"], cars_data[\"selling_price\"], c = \"black\")\n",
    "plt.xlabel(\"engine\")\n",
    "plt.ylabel(\"selling_price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a1001c",
   "metadata": {},
   "source": [
    "*Comment: It is hard to tell if there is any clear relationship between the selling price and the engine from this graph.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb70c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The relationship between \"selling_price\" and \"max_power\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(cars_data[\"max_power\"], cars_data[\"selling_price\"], c = \"grey\")\n",
    "plt.xlabel(\"max_power\")\n",
    "plt.ylabel(\"selling_price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fffedbd",
   "metadata": {},
   "source": [
    "*Comment: It is hard to tell if there is any clear relationship between the selling price and the maximum power of the cars from this graph.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22214be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The relationship between \"selling_price\" and \"seats\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(cars_data[\"seats\"], cars_data[\"selling_price\"], c = \"red\")\n",
    "plt.xlabel(\"seats\")\n",
    "plt.ylabel(\"selling_price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8b4ef3",
   "metadata": {},
   "source": [
    "*Comment: It is hard to tell if there is any clear relationship between the selling price and the number of seats of the cars from this graph.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92045c5d",
   "metadata": {},
   "source": [
    "### 4. Estimations\n",
    "\n",
    "**You will train two different models: a random forest and a SVM.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dd3520",
   "metadata": {},
   "source": [
    "**4.1 A first model: Random forest**\n",
    "\n",
    "You will first try to predict the selling price of the cars using a random forest. You will make 3 hyperparameters vary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10e992e",
   "metadata": {},
   "source": [
    "**1. Using a random forest algorithm, predict the selling price of the car in the training set uing the following variables: year, fuel, km_driven.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "864b7799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorial independent variable with label encoder\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create arrary of categorial variable to be encoded\n",
    "\n",
    "categorical_col = [\"fuel\"]\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply label encoder on categorical feature column\n",
    "\n",
    "training[categorical_col] = training[categorical_col].apply(lambda col: le.fit_transform(col))\n",
    "test[categorical_col] = test[categorical_col].apply(lambda col: le.fit_transform(col))\n",
    "validation[categorical_col] = validation[categorical_col].apply(lambda col: le.fit_transform(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a052043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=3, min_samples_leaf=10, n_estimators=20,\n",
       "                      random_state=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimation\n",
    "\n",
    "# First model: Random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "y_training = training.selling_price\n",
    "X_training = training[[\"year\", \"fuel\", \"km_driven\"]]\n",
    "\n",
    "y_validation = validation.selling_price\n",
    "X_validation = validation[[\"year\", \"fuel\", \"km_driven\"]]\n",
    "\n",
    "y_test = test.selling_price\n",
    "X_test = test[[\"year\", \"fuel\", \"km_driven\"]]\n",
    "\n",
    "# Train model on the training dataset\n",
    "\n",
    "# X, y = make_regression(n_features = 3)\n",
    "\n",
    "regr_train = RandomForestRegressor(n_estimators = 20, max_features = 3, min_samples_leaf = 10, random_state = 0)\n",
    "regr_train.fit(X_training, y_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75df887",
   "metadata": {},
   "source": [
    "**2. Compute the mean squared error both for the training and the validation datasets. Compare them with each other.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04995f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for the train set is 207751147160.7179\n",
      "MSE for the validation set is 252762070921.7599\n"
     ]
    }
   ],
   "source": [
    "# Assess the goodness of fit by computing MSE on the training and validation dataset\n",
    "\n",
    "y_pred_train = regr_train.predict(X_training)\n",
    "y_pred_validation = regr_train.predict(X_validation)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_trained = mean_squared_error(y_training, y_pred_train)\n",
    "print(\"MSE for the train set is\", mse_trained)\n",
    "mse_validated = mean_squared_error(y_validation, y_pred_validation)\n",
    "print(\"MSE for the validation set is\", mse_validated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcca120",
   "metadata": {},
   "source": [
    "*Comment: The MSE for the validation test is slightly higher than that for the train set.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ddec0c",
   "metadata": {},
   "source": [
    "**3. Now, using a loop, make the minimum size of terminal nodes vary as follows: 10, 20, 30, . . . , 100. At each iteration, compute the mean squared error (and store it) for both samples.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad9153c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node 10  - MSE_train: 207751147160.7179  - MSE_validation: 252762070921.7599\n",
      "node 20  - MSE_train: 227911009970.1841  - MSE_validation: 258695669783.84253\n",
      "node 30  - MSE_train: 253904414516.11432  - MSE_validation: 276695808672.6283\n",
      "node 40  - MSE_train: 294690236541.9102  - MSE_validation: 313114805678.8977\n",
      "node 50  - MSE_train: 321156558712.8613  - MSE_validation: 333788084606.0197\n",
      "node 60  - MSE_train: 349518782105.71564  - MSE_validation: 371158863748.0613\n",
      "node 70  - MSE_train: 361490346131.10284  - MSE_validation: 380217939172.8407\n",
      "node 80  - MSE_train: 378065228522.1013  - MSE_validation: 397136505256.0076\n",
      "node 90  - MSE_train: 381204341352.81006  - MSE_validation: 398831928822.9421\n",
      "node 100  - MSE_train: 382044702876.8574  - MSE_validation: 400823719863.7507\n"
     ]
    }
   ],
   "source": [
    "mse_train_node = []\n",
    "mse_validation_node = []\n",
    "\n",
    "for i in range(10, 110, 10):\n",
    "    reg = RandomForestRegressor(n_estimators = 20, max_features = 3, min_samples_leaf = i, random_state = 0)\n",
    "    reg.fit(X_training, y_training)\n",
    "    # Predict for the training set\n",
    "    y_train_pred = reg.predict(X_training)\n",
    "    # Calculate the MSE on the training set\n",
    "    mse_train = mean_squared_error(y_training, y_train_pred)\n",
    "    mse_train_node.append(mse_train)\n",
    "   \n",
    "    # Predict for the validation set\n",
    "    y_validation_pred = reg.predict(X_validation)\n",
    "    # Calculate the MSE on the validation set\n",
    "    mse_validation = mean_squared_error(y_validation, y_validation_pred)\n",
    "    mse_validation_node.append(mse_validation)\n",
    "    \n",
    "    print(\"node\", i, \" - MSE_train:\", mse_train,  \" - MSE_validation:\", mse_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9ac837",
   "metadata": {},
   "source": [
    "**4. On a graph, plot the mean squared error as a function of the node size, for both samples (one curve for each sample). Comment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a051f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean squared error as a function of the node size for the train and validation set\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nodes = range(10, 110, 10)\n",
    "plt.figure()\n",
    "plt.plot(nodes, mse_train_node, label = \"MSE for the train set\")\n",
    "plt.plot(nodes, mse_validation_node, label = \"MSE for the validation set\")\n",
    "plt.xlabel(\"Nodes\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE for different node sizes\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a24a2",
   "metadata": {},
   "source": [
    "*Comment: As the nodes increase, it can be seen that the MSEs for both the train and validation set also increase.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c403dd",
   "metadata": {},
   "source": [
    "**5. What are the values for your hyperparameters (the number of trees, the number of variables randomly sampled as candidates at each split, and the minimum size of terminal nodes) that provide the best fit with regard to the MSE?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e43890e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AMSE\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "18 fits failed out of a total of 54.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AMSE\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AMSE\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\AMSE\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AMSE\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AMSE\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AMSE\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AMSE\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AMSE\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AMSE\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AMSE\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AMSE\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AMSE\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AMSE\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 308, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\AMSE\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [-2.84061057e+11 -2.79183919e+11 -3.39007713e+11 -3.41142421e+11\n",
      " -3.70539059e+11 -3.64967582e+11 -2.53453668e+11 -2.53370245e+11\n",
      " -2.85938958e+11 -2.85712401e+11 -3.23790643e+11 -3.23494621e+11\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\AMSE\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [-2.60074542e+11 -2.55107984e+11 -3.26565058e+11 -3.27794415e+11\n",
      " -3.60978227e+11 -3.54151252e+11 -2.12746908e+11 -2.12589149e+11\n",
      " -2.58506665e+11 -2.58781031e+11 -3.03777295e+11 -3.03833617e+11\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=3, min_samples_leaf=10, n_estimators=500,\n",
       "                      random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The best fit with regard to the MSE\n",
    "\n",
    "# parameter grid\n",
    "param_grid = {\"n_estimators\": [100, 500], \n",
    "              \"max_features\": [1, 3, 5],\n",
    "              \"min_samples_leaf\": [10, 20, 30]\n",
    "             }\n",
    "\n",
    "# Create a regression tree\n",
    "tree_reg = RandomForestRegressor(random_state = 0)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(tree_reg, # model\n",
    "                          param_grid, # parameter grid\n",
    "                          scoring = \"neg_mean_squared_error\", # metric to evaluate\n",
    "                          return_train_score = True,\n",
    "                          cv = 3)\n",
    "\n",
    "# CV using all parameter combinations in the grid\n",
    "grid_search.fit(X_training, y_training)\n",
    "\n",
    "# the best hyperparameters\n",
    "grid_search.best_params_\n",
    "\n",
    "# the best model\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c911875",
   "metadata": {},
   "source": [
    "*Comment: The model which provides the best fit with regard to MSE has the hyperpameters as follows:*\n",
    "\n",
    "*Number of tree: 500*\n",
    "\n",
    "*Number of variables randomly sampled as candidates at each split: 3*\n",
    "\n",
    "*Minimum size of terminal nodes: 10*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd1f7e",
   "metadata": {},
   "source": [
    "**4.2 A second model: SVM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38e4232",
   "metadata": {},
   "source": [
    "**1. Using a Support Vector Machine (SVM) with a linear kernel, predict the selling price of the car in the training set. Use the following variables: year, fuel, km_driven.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ffab056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AMSE\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=10, kernel='linear')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Rescale features\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_X = StandardScaler().fit(X_training)\n",
    "X_training_sc = scaler_X.transform(X_training)\n",
    "X_validation_sc = scaler_X.transform(X_validation)\n",
    "X_test_sc = scaler_X.transform(X_test)\n",
    "\n",
    "# Reshape the target variable before rescaling\n",
    "\n",
    "y_training_reshape = y_training.values.reshape(-1, 1)\n",
    "y_validation_reshape = y_validation.values.reshape(-1, 1)\n",
    "y_test_reshape = y_test.values.reshape(-1, 1)\n",
    "\n",
    "# Rescale the target variable\n",
    "\n",
    "scaler_y = StandardScaler().fit(y_training_reshape)\n",
    "y_training_sc = scaler_y.transform(y_training_reshape)\n",
    "y_validation_sc = scaler_y.transform(y_validation_reshape)\n",
    "y_test_sc = scaler_y.transform(y_test_reshape)\n",
    "\n",
    "# Now we can fit the SVM model\n",
    "\n",
    "SVR_train = SVR(kernel = \"linear\", C = 10)\n",
    "SVR_train.fit(X_training_sc, y_training_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf07b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A way to make pipeline to rescale the data\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# model_SVM = make_pipeline(StandardScaler(), SVR(C=10, kernel = \"linear\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a5f2a0",
   "metadata": {},
   "source": [
    "**2. Compute the mean squared error both for the training and the validation datasets. Compare them with each other.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bb0e06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for the train set is 0.8751868466029036\n",
      "MSE for the validation set is 0.9662448253450787\n"
     ]
    }
   ],
   "source": [
    "# Assess the goodness of fit by computing MSE on the training and validation dataset\n",
    "\n",
    "y_pred_train_SVM = SVR_train.predict(X_training_sc)\n",
    "y_pred_validation_SVM = SVR_train.predict(X_validation_sc)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_trained_SVM = mean_squared_error(y_training_sc, y_pred_train_SVM)\n",
    "print(\"MSE for the train set is\", mse_trained_SVM)\n",
    "mse_validated_SVM = mean_squared_error(y_validation_sc, y_pred_validation_SVM)\n",
    "print(\"MSE for the validation set is\", mse_validated_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75027f1a",
   "metadata": {},
   "source": [
    "*Comment: The MSE for both the train and validation set are relatively low. The MSE for the validation test is fairly higher than that for the test set.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc38f173",
   "metadata": {},
   "source": [
    "**3. Now, using a loop, make the costs vary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e4346ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost 1000.0  - MSE_train_SVM: 558820713547.1471  - MSE_validation_SVM: 617438758758.6605\n",
      "Cost 790.6043210907702  - MSE_train_SVM: 560160314067.5717  - MSE_validation_SVM: 618944779801.4979\n",
      "Cost 625.0551925273976  - MSE_train_SVM: 561335897976.6921  - MSE_validation_SVM: 620263480639.6525\n",
      "Cost 494.1713361323833  - MSE_train_SVM: 562589490889.418  - MSE_validation_SVM: 621721395293.3711\n",
      "Cost 390.6939937054617  - MSE_train_SVM: 563809420142.723  - MSE_validation_SVM: 623158017197.1583\n",
      "Cost 308.88435964774817  - MSE_train_SVM: 565899882364.426  - MSE_validation_SVM: 625577876976.5743\n",
      "Cost 244.205309454865  - MSE_train_SVM: 568794505819.5822  - MSE_validation_SVM: 628959636411.6649\n",
      "Cost 193.06977288832496  - MSE_train_SVM: 571266907725.111  - MSE_validation_SVM: 631822717189.0901\n",
      "Cost 152.64179671752333  - MSE_train_SVM: 574294695681.4849  - MSE_validation_SVM: 635267787477.3677\n",
      "Cost 120.67926406393289  - MSE_train_SVM: 578527631031.9647  - MSE_validation_SVM: 640064176676.4885\n",
      "Cost 95.40954763499938  - MSE_train_SVM: 583511114424.0408  - MSE_validation_SVM: 645680048245.0525\n",
      "Cost 75.43120063354615  - MSE_train_SVM: 588339633986.3302  - MSE_validation_SVM: 651128872947.9736\n",
      "Cost 59.63623316594643  - MSE_train_SVM: 593443114692.3638  - MSE_validation_SVM: 656940339449.8875\n",
      "Cost 47.14866363457394  - MSE_train_SVM: 601547537060.2499  - MSE_validation_SVM: 666047973263.8007\n",
      "Cost 37.2759372031494  - MSE_train_SVM: 609516343195.1769  - MSE_validation_SVM: 675011883128.0851\n",
      "Cost 29.4705170255181  - MSE_train_SVM: 618221266141.7225  - MSE_validation_SVM: 684744940095.1255\n",
      "Cost 23.29951810515372  - MSE_train_SVM: 626353326021.3292  - MSE_validation_SVM: 693831549090.0475\n",
      "Cost 18.420699693267164  - MSE_train_SVM: 634142183592.9907  - MSE_validation_SVM: 702499174908.4739\n",
      "Cost 14.563484775012437  - MSE_train_SVM: 640849695569.2156  - MSE_validation_SVM: 709953725064.7368\n",
      "Cost 11.513953993264469  - MSE_train_SVM: 646564988029.7953  - MSE_validation_SVM: 716275933394.7836\n",
      "Cost 9.102981779915218  - MSE_train_SVM: 651411601892.0973  - MSE_validation_SVM: 721618869323.907\n",
      "Cost 7.196856730011521  - MSE_train_SVM: 655360760592.31  - MSE_validation_SVM: 725966032705.8025\n",
      "Cost 5.689866029018293  - MSE_train_SVM: 659301824523.1781  - MSE_validation_SVM: 730276110575.441\n",
      "Cost 4.498432668969444  - MSE_train_SVM: 661784157828.6866  - MSE_validation_SVM: 733002907133.049\n",
      "Cost 3.5564803062231287  - MSE_train_SVM: 663565388055.0294  - MSE_validation_SVM: 734961652372.1683\n",
      "Cost 2.8117686979742307  - MSE_train_SVM: 664957199669.4646  - MSE_validation_SVM: 736490272785.6718\n",
      "Cost 2.2229964825261956  - MSE_train_SVM: 666086438444.8691  - MSE_validation_SVM: 737729753099.7892\n",
      "Cost 1.7575106248547911  - MSE_train_SVM: 666985126414.0723  - MSE_validation_SVM: 738715057250.3774\n",
      "Cost 1.3894954943731375  - MSE_train_SVM: 667578033904.5505  - MSE_validation_SVM: 739367161194.3564\n",
      "Cost 1.0985411419875584  - MSE_train_SVM: 668050699232.2266  - MSE_validation_SVM: 739886585078.4403\n",
      "Cost 0.868511373751352  - MSE_train_SVM: 668426834513.3367  - MSE_validation_SVM: 740299661364.2513\n",
      "Cost 0.6866488450042998  - MSE_train_SVM: 668725736345.9263  - MSE_validation_SVM: 740627752343.2928\n",
      "Cost 0.5428675439323859  - MSE_train_SVM: 668963004294.4366  - MSE_validation_SVM: 740888086999.021\n",
      "Cost 0.42919342601287785  - MSE_train_SVM: 669151186205.0388  - MSE_validation_SVM: 741094499073.6414\n",
      "Cost 0.33932217718953295  - MSE_train_SVM: 669304524449.7205  - MSE_validation_SVM: 741262556683.2777\n",
      "Cost 0.2682695795279725  - MSE_train_SVM: 669421795866.8331  - MSE_validation_SVM: 741391152219.0319\n",
      "Cost 0.21209508879201905  - MSE_train_SVM: 669514658368.6808  - MSE_validation_SVM: 741492966029.4478\n",
      "Cost 0.16768329368110083  - MSE_train_SVM: 669588167879.9954  - MSE_validation_SVM: 741573551491.0565\n",
      "Cost 0.13257113655901082  - MSE_train_SVM: 669646342332.4133  - MSE_validation_SVM: 741637319599.7109\n",
      "Cost 0.10481131341546852  - MSE_train_SVM: 669692371256.0046  - MSE_validation_SVM: 741687770504.1586\n",
      "Cost 0.08286427728546843  - MSE_train_SVM: 669728784392.7075  - MSE_validation_SVM: 741727679435.5527\n",
      "Cost 0.0655128556859551  - MSE_train_SVM: 669757586821.4294  - MSE_validation_SVM: 741759245503.0995\n",
      "Cost 0.05179474679231213  - MSE_train_SVM: 669780366925.2489  - MSE_validation_SVM: 741784210456.9799\n",
      "Cost 0.040949150623804276  - MSE_train_SVM: 669798382461.256  - MSE_validation_SVM: 741803953285.671\n",
      "Cost 0.0323745754281764  - MSE_train_SVM: 669812629051.856  - MSE_validation_SVM: 741819565444.3179\n",
      "Cost 0.025595479226995333  - MSE_train_SVM: 669823894611.8748  - MSE_validation_SVM: 741831910605.2003\n",
      "Cost 0.020235896477251554  - MSE_train_SVM: 669832802552.3805  - MSE_validation_SVM: 741841672068.3531\n",
      "Cost 0.015998587196060572  - MSE_train_SVM: 669839846046.2572  - MSE_validation_SVM: 741849390351.8843\n",
      "Cost 0.012648552168552958  - MSE_train_SVM: 669845415186.5115  - MSE_validation_SVM: 741855492978.1053\n",
      "Cost 0.01  - MSE_train_SVM: 669849818500.1134  - MSE_validation_SVM: 741860318064.4863\n"
     ]
    }
   ],
   "source": [
    "mse_train_SVM = []\n",
    "mse_validation_SVM = []\n",
    "\n",
    "for i in 10**np.linspace(start=3, stop=-2, num=50):\n",
    "    SVM_model = SVR(kernel = \"linear\", C = i)\n",
    "    SVM_model.fit(X_training_sc, y_training)\n",
    "    \n",
    "    # Predict for the training set\n",
    "    y_train_pred_SVM = SVM_model.predict(X_training_sc)\n",
    "    \n",
    "    # Calculate the MSE on the training set\n",
    "    mse_train_SVM_value = mean_squared_error(y_training, y_train_pred_SVM)\n",
    "    mse_train_SVM.append(mse_train_SVM_value)\n",
    "    \n",
    "    # Predict for the validation set\n",
    "    y_validation_pred_SVM = SVM_model.predict(X_validation_sc)\n",
    "    \n",
    "    # Calculate the MSE on the validation set\n",
    "    mse_validation_SVM_value = mean_squared_error(y_validation, y_validation_pred_SVM)\n",
    "    mse_validation_SVM.append(mse_validation_SVM_value)\n",
    "    \n",
    "    print(\"Cost\", i, \" - MSE_train_SVM:\", mse_train_SVM_value,  \" - MSE_validation_SVM:\", mse_validation_SVM_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac596c68",
   "metadata": {},
   "source": [
    "**4. On a graph, plot the mean squared error as a function of the node size, for both samples (one curve for each sample). Comment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bfdb243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the mean squared error as a function of the cost for the train and validation set\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "costs = 10**np.linspace(start=3, stop=-2, num=50)\n",
    "plt.figure()\n",
    "plt.plot(costs, mse_train_SVM, label = \"MSE for the train set\")\n",
    "plt.plot(costs, mse_validation_SVM, label = \"MSE for the validation set\")\n",
    "plt.xlabel(\"Costs\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE for different costs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b0e4e2",
   "metadata": {},
   "source": [
    "*Comment: As can be seen from the graph, the MSE decreases sharply after increasing the cost from 0 to roughly 100, and then decreases at a lower pace for the cost varying from 200 to 1000. Additionally, the MSE for the validation set is higher than that for the train set.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213a4f79",
   "metadata": {},
   "source": [
    "**5. What are the values for your hyperparameters (the number of trees, the number of variables randomly sampled as candidates at each split, and the minimum size of terminalnodes) that provide the best fit with regard to the MSE?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4709ba38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1400, kernel='linear')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The best fit with regard to the MSE\n",
    "\n",
    "# parameter grid\n",
    "param_grid = {\"kernel\": [\"linear\", \"rbf\"], \n",
    "              \"C\": [1000, 1100, 1200, 1300, 1400]\n",
    "             }\n",
    "\n",
    " # Create a SVM tree\n",
    "tree_SVM = SVR()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search_SVM = GridSearchCV(tree_SVM, # model\n",
    "                          param_grid, # parameter grid\n",
    "                          scoring = \"neg_mean_squared_error\", # metric to evaluate\n",
    "                          return_train_score = True,\n",
    "                          cv = 3)\n",
    "\n",
    "# CV using all parameter combinations in the grid\n",
    "grid_search_SVM.fit(X_training_sc, y_training)\n",
    "\n",
    "# the best hyperparameters\n",
    "grid_search_SVM.best_params_\n",
    "\n",
    "# the best model\n",
    "grid_search_SVM.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ed6084",
   "metadata": {},
   "source": [
    "*Comment: The result from the previous question suggests that the SME decreases when increasing the costs. That's why I chose the costs from 1100 to 1400 to test in this grid, since there's no clear instruction on how to choose the costs.*\n",
    "\n",
    "*Among the models having two types of kernel, \"linear\" or \"rbf\", and the costs varying from [1000, 1100, 1200, 1300, 1400], the model which provides the best fit has the hyperparameters as follows:*\n",
    "\n",
    "*The kernel: linear*\n",
    "\n",
    "*The cost: 1400 - the highest in the grid*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c4f72f",
   "metadata": {},
   "source": [
    "### 4.3 Select your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855270cf",
   "metadata": {},
   "source": [
    "**1. Compute the MSE on the test set for the random forest with the selected values for the hyperparameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d2c2327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for the best RandomForest model is 315954584193.0168\n"
     ]
    }
   ],
   "source": [
    "# Compute the MSE on the test set for the random forest with the selected values for the hyperparameters\n",
    "\n",
    "# Random Forest\n",
    "regr_best = RandomForestRegressor(n_estimators = 500, max_features = 3, min_samples_leaf = 10, random_state = 0)\n",
    "regr_best.fit(X_test, y_test)\n",
    "\n",
    "# Assess the goodness of fit by computing MSE on the training and validation dataset\n",
    "y_pred_best = regr_best.predict(X_test)\n",
    "\n",
    "mse_best_RandomForest = mean_squared_error(y_test, y_pred_best)\n",
    "print(\"MSE for the best RandomForest model is\", mse_best_RandomForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd45cdc2",
   "metadata": {},
   "source": [
    "**2. Do the same for your best SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c0f0bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for the best SVM model is 590825491070.8698\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "SVM_best = SVR(kernel = \"linear\", C = 1000)\n",
    "SVM_best.fit(X_test_sc, y_test)\n",
    "\n",
    "# Assess the goodness of fit by computing MSE on the training and validation dataset\n",
    "y_pred_best_SVM = SVM_best.predict(X_test_sc)\n",
    "\n",
    "mse_best_SVM = mean_squared_error(y_test, y_pred_best_SVM)\n",
    "print(\"MSE for the best SVM model is\", mse_best_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36707d4",
   "metadata": {},
   "source": [
    "**3. Which model gives the best results on the test set? Comment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95e8b65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_best_RandomForest < mse_best_SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c3fa5b",
   "metadata": {},
   "source": [
    "*Comment: Regarding to the MSE, the RandomForest model provides better result comparing to the SVM as the MSE for the former is smaller than that for the latter.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
